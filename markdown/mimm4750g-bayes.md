# MIMM4750G
## Bayesian inference
<img src="/img/xkcd-bayes.png"/>

---

# Maximum likelihood

* Recall that likelihood is focusing on the probability as a function of the model parameters (hypothesis) given the data.
* For a given data set, we want to find the maximum likelhood estimate (MLE) of the parameters ($\theta$) of the model:
$$\hat{\theta} = \argmax_\theta P(D|\theta)$$
* If the data are truly generated by a distribution covered by our model, then the MLE is guaranteed to find the true parameters with enough data.

---

* The maximum likelihood estimate (MLE) is a single (combination of) parameter value(s).
* This is a [frequentist](https://en.wikipedia.org/wiki/Frequentist_inference) approach.
  * We want to repeat our experiment (take many samples) so we can converge to a true value that exists in the universe!
* If the likelihood function is "rugged" and we don't have enough data, then there may be many parameter values that are about as good as the MLE!

![](/img/noisy.svg)

---

# Being Bayesian

* A Bayesian believes that you can never do the same experiment twice.
  * You never see exactly the same patient twice, but you have your prior experience from previous visits.
* A Bayesian would object to relying on a single estimate
  * It is more robust to refer to the **distribution** of parameters that are supported by the data.
* A Bayesian understands that science is always subjective.
  * The design of an experiment is shaped by an investigator's **subjective belief** about the outcome.

---

# Conditional probability

* We are used to thinking about the probability of an outcome, $P(D)$
* This implicitly involves some model (hypothesis), $P(D|H)$.
* We say that $P(D|H)$ is "the probability of the data, conditional on the hypothesis being true".  This is the likelihood.
<img src="/img/conditional.png" width="550px"/>

---

# Joint probability

* We can calculate the **joint probability** that both D and H are true:
  <img src="/img/conditional2.png"/>

  $$P(D,H) = P(D|H) \times P(H)$$

* It's perfectly valid to swap D and H!

  $$P(D,H) = P(H|D) \times P(D)$$

---

# Bayes' theorem

* This leads to something outrageous and wonderful:

![](/img/bayes.png)

---

# Belief

* This formula has some strange quantities.
  * $P(D|H)$ is the likelihood.
  * $P(D)$ is the probability of the data. *Weird.*
  * $P(H)$ is the probability of the hypothesis without any data.
* If we have no data, then we can only work with our *prior belief*.
  * $P(H|D)$ is then our updated belief *after we have seen the data*.  It is the posterior belief.


---

# Reasons why people don't like Bayesian inference

* "Belief doesn't seem scientific."
* "How am I supposed to decide what my prior belief is?"
* "The prior is biasing your study."
* Computationally hard for complex problems.

<img src="https://imgs.xkcd.com/comics/modified_bayes_theorem.png" height=250/>

---

# Embrace the prior

<table>
  <tr>
    <td style="font-size: 20pt;">
        <ul>
            <li>Priors are natural: I have an expectation that when I toss a coin toss, it will come up heads about 50% of the time.</li>
            <li>Priors are flexible (unless you have very little data).</li>
            <li>(right) Updating prior with 10, 50 and 250 coin tosses given true probability is 50%.</li>
        </ul>
    </td>
    <td width="55%">
        <img src="/img/update-prior.png" width="700px"/>
    </td>
  </tr>
</table>

---

# Choosing your prior

<table>
  <tr>
    <td style="font-size: 20pt;">
      <ul>
      <li>There are many probability distributions that we can use as priors.</li>
      <li>Distributions have different limits (<i>e.g.</i>, bounded on the left)</li>
      <li>People tend to prefer setting distributions to be "uninformative".</li>
      <li>Be careful!  What seems uninformative might not be.</li>
      </ul>
    </td>
    <td width="45%">
      <img src="/img/priors.png" width="600px"/>
    </td>
  </tr>
</table>

---

# Hyperparameters

* Prior distributions have one or more parameters.
  * For example, the uniform distribution has lower and upper limits.
* Since we want to use "parameters" to refer to those in the model we are trying to fit, we call this other set "hyperparameters".
* We might also use previously collected data to choose hyperparameters.
  * For example, the mean hyperparameter of a Gaussian prior can be the mean of a previous data set <i>i.e.,</i> hierarchical Bayes.

---

# Getting rid of P(D)

* We could calculate $P(D)$ exactly by integrating $P(D|H)$ over *all possible hypotheses*:
  $$P(D) = \int_H P(D|H) P(H)$$

* It is often not possible to solve for this integral.
* We need to take a different approach...

---

# What do we *really* want?

* We don't really care what the absolute posterior value is for a given value $H$ &mdash; we want to know relative differences.
* Since the data are not going to change, we can just drop it:

$$P(H|D) \propto P(D|H) P(H)$$

* Our posterior belief is *proportional* to our prior belief, times the likelihood of the data.
  * This is going to become really important later!

---

# Conjugate priors

* In some cases, multiplying the likelhood and prior yields a posterior distribution that is the same type as the prior.
  * When this works, the prior distribution is called a *conjugate prior*.

| Likelihood | Prior      | Posterior |
|------------|------------|-----------|
| Binomial   | Beta       | Beta      |
| Negative binomial | Beta  | Beta |
| Poisson | Gamma | Gamma |
| Geometric | Beta | Beta |
| Exponential | Gamma | Gamma |
| Normal (unknown mean) | Normal | Normal |
| Normal (unknown variance) | Inverse gamma | Inverse gamma |
| Multinomial | Dirichlet | Dirichlet |

---

# Beta-binomial

* Remember the likelihood of coin tosses is modeled with a binomial distribution:
  $$L\propto p^y (1-p)^{N-y}$$
* The beta distribution is a good choice for probability parameters, because it is bounded on the interval [0,1]:
  $$\mathrm{Beta}(\alpha,\beta)=\frac{1}{B(\alpha,\beta)} p^{\alpha-1}(1-p)^{\beta-1}$$


---

* The posterior updates the hyperparameters $\alpha$ and $\beta$ to $\alpha+y$ and $\beta+N-y$.
![](/img/beta-binom.svg)

---

# Sampling from the posterior

* We usually can't write down a [closed form expression](https://en.wikipedia.org/wiki/Closed-form_expression) for P(H|D) as a distribution function.
* The next best thing would be to generate a random sample from this distribution.
* There are a number of ways to go about this (rejection sampling), but we will focus specifically on Markov chain Monte Carlo (MCMC) sampling.

---

<section data-background="#333" style="color:white">

<h1 style="color:white">Key points</h1>

* Bayesian inference is about updating your prior belief about the model with data.
* We use a probability distribution to represent our belief.
  * The parameters of the prior distribution are called *hyperparameters*.  We cannot estimate them from the data.
* The posterior belief is proportional the likelihood times the prior probability.
  * At some point we will have to deal with the probability of the data (integrated over all possible parameter values).

</section>
